{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = 'Dataset'\n",
    "IMAGE_FOR_MATCHING_PATH = 'DatasetForMatching'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_match_percentage(img1, img2, feature_detector):\n",
    "    \"\"\"Compute the match percentage between two images using keypoints and RANSAC.\"\"\"\n",
    "    \n",
    "    # Detect keypoints and compute descriptors for both images\n",
    "    keypoints1, descriptors1 = feature_detector.detectAndCompute(img1, None)\n",
    "    keypoints2, descriptors2 = feature_detector.detectAndCompute(img2, None)\n",
    "\n",
    "    if isinstance(feature_detector, cv2.ORB):  # ORB uses binary descriptors (Hamming distance)\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        matches = bf.match(descriptors1, descriptors2)\n",
    "    else:\n",
    "        # For SIFT or other detectors, use FLANN (descriptors are float32)\n",
    "        index_params = dict(algorithm=1, trees=5)\n",
    "        search_params = dict(checks=50)\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    # Lowe's ratio test (only for FLANN-based matching)\n",
    "    if not isinstance(feature_detector, cv2.ORB):\n",
    "        good_matches = [m for m, n in matches if m.distance < 0.7 * n.distance]\n",
    "    else:\n",
    "        good_matches = matches  # No need for ratio test in BFMatcher with crossCheck=True\n",
    "\n",
    "    # Estimate homography using RANSAC if there are enough good matches\n",
    "    valid_matches = 0\n",
    "    if len(good_matches) >= 4:\n",
    "        src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        _, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        if mask is not None:\n",
    "            valid_matches = sum(mask.ravel())\n",
    "\n",
    "    total_keypoints = len(keypoints1)\n",
    "    match_percentage = (valid_matches / total_keypoints * 100) if total_keypoints > 0 else 0\n",
    "    return len(keypoints1), valid_matches, match_percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(dataset_path, matching_images_path):\n",
    "    data = []\n",
    "    matching_images = {}\n",
    "    for f in os.listdir(matching_images_path):\n",
    "        if f.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(matching_images_path, f)\n",
    "            preprocessed_image = preprocess_image(img_path)\n",
    "            matching_images[os.path.basename(f)] = preprocessed_image\n",
    "\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        nominal_label = os.path.basename(root)\n",
    "        print(f\"Processing {nominal_label}\")\n",
    "        \n",
    "        for file in tqdm(files):\n",
    "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "\n",
    "                img_path = os.path.join(root, file)\n",
    "                img_preprocessed = preprocess_image(img_path)\n",
    "                img = cv2.imread(img_path)\n",
    "\n",
    "                # Collect image metadata\n",
    "                img_name = os.path.basename(file)\n",
    "                height, width = img.shape[:2]\n",
    "                total_pixels = height * width\n",
    "                avg_color_R, avg_color_G, avg_color_B = img.mean(axis=(0, 1)).tolist()\n",
    "\n",
    "                # Match with each image in DatasetForMatching\n",
    "                sift_match_results = {}\n",
    "                for match_name, match_img in matching_images.items():\n",
    "                    _, _, match_percentage = compute_match_percentage(img_preprocessed, match_img, feature_detector = cv2.SIFT_create())\n",
    "                    sift_match_results[f\"sift_match_percentage_with_{match_name}\"] = match_percentage\n",
    "\n",
    "                orb_match_results = {}\n",
    "                for match_name, match_img in matching_images.items():\n",
    "                    _, _, match_percentage = compute_match_percentage(img_preprocessed, match_img, feature_detector = cv2.ORB_create())\n",
    "                    orb_match_results[f\"orb_match_percentage_with_{match_name}\"] = match_percentage\n",
    "\n",
    "                # Append data\n",
    "                row = {\n",
    "                    \"image_name\": img_name,\n",
    "                    \"nominal_label\": nominal_label,\n",
    "                    \"total_pixels\": total_pixels,\n",
    "                    \"avg_color_R\": avg_color_R,\n",
    "                    \"avg_color_G\": avg_color_G,\n",
    "                    \"avg_color_B\": avg_color_B,\n",
    "                    **sift_match_results,\n",
    "                    **orb_match_results\n",
    "                }\n",
    "                data.append(row)\n",
    "\n",
    "    # Save as a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"rupiah_classification.csv\", index=False)\n",
    "    print(\"Dataset saved as rupiah_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [1:08:22<00:00, 32.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [13:53<00:00,  6.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [1:22:22<00:00, 38.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [1:07:28<00:00, 31.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [1:09:28<00:00, 32.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [58:50<00:00, 27.58s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [08:18<00:00,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as rupiah_classification.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Paths to the dataset folders\n",
    "generate_dataset(IMAGE_PATH, IMAGE_FOR_MATCHING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>nominal_label</th>\n",
       "      <th>total_pixels</th>\n",
       "      <th>avg_color_R</th>\n",
       "      <th>avg_color_G</th>\n",
       "      <th>avg_color_B</th>\n",
       "      <th>sift_match_percentage_with_belakang_100k.jpg</th>\n",
       "      <th>sift_match_percentage_with_belakang_10k.jpg</th>\n",
       "      <th>sift_match_percentage_with_belakang_1k.jpg</th>\n",
       "      <th>sift_match_percentage_with_belakang_20k.jpg</th>\n",
       "      <th>...</th>\n",
       "      <th>orb_match_percentage_with_belakang_2k.jpg</th>\n",
       "      <th>orb_match_percentage_with_belakang_50k.jpg</th>\n",
       "      <th>orb_match_percentage_with_belakang_5k.jpg</th>\n",
       "      <th>orb_match_percentage_with_depan_100k.jpg</th>\n",
       "      <th>orb_match_percentage_with_depan_10k.jpg</th>\n",
       "      <th>orb_match_percentage_with_depan_1k.jpg</th>\n",
       "      <th>orb_match_percentage_with_depan_20k.jpg</th>\n",
       "      <th>orb_match_percentage_with_depan_2k.jpg</th>\n",
       "      <th>orb_match_percentage_with_depan_50k.jpg</th>\n",
       "      <th>orb_match_percentage_with_depan_5k.jpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_20241214_181230.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>12000000</td>\n",
       "      <td>93.222060</td>\n",
       "      <td>108.722223</td>\n",
       "      <td>119.818832</td>\n",
       "      <td>0.094594</td>\n",
       "      <td>0.174736</td>\n",
       "      <td>0.059121</td>\n",
       "      <td>0.063062</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_20241214_181244.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>12000000</td>\n",
       "      <td>140.698959</td>\n",
       "      <td>153.735422</td>\n",
       "      <td>161.946505</td>\n",
       "      <td>0.052033</td>\n",
       "      <td>0.212724</td>\n",
       "      <td>0.021425</td>\n",
       "      <td>0.035199</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_20241214_181308.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>12000000</td>\n",
       "      <td>83.061434</td>\n",
       "      <td>97.298658</td>\n",
       "      <td>97.750542</td>\n",
       "      <td>0.222297</td>\n",
       "      <td>0.092062</td>\n",
       "      <td>0.042663</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_20241214_181328.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>12000000</td>\n",
       "      <td>123.816459</td>\n",
       "      <td>153.400466</td>\n",
       "      <td>155.280630</td>\n",
       "      <td>0.201326</td>\n",
       "      <td>0.267918</td>\n",
       "      <td>0.034070</td>\n",
       "      <td>0.068141</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_20241214_181348.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>12000000</td>\n",
       "      <td>120.363446</td>\n",
       "      <td>133.425556</td>\n",
       "      <td>151.094102</td>\n",
       "      <td>0.116144</td>\n",
       "      <td>0.223179</td>\n",
       "      <td>0.034160</td>\n",
       "      <td>0.063765</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                image_name  nominal_label  total_pixels  avg_color_R  \\\n",
       "0  IMG_20241214_181230.jpg           1000      12000000    93.222060   \n",
       "1  IMG_20241214_181244.jpg           1000      12000000   140.698959   \n",
       "2  IMG_20241214_181308.jpg           1000      12000000    83.061434   \n",
       "3  IMG_20241214_181328.jpg           1000      12000000   123.816459   \n",
       "4  IMG_20241214_181348.jpg           1000      12000000   120.363446   \n",
       "\n",
       "   avg_color_G  avg_color_B  sift_match_percentage_with_belakang_100k.jpg  \\\n",
       "0   108.722223   119.818832                                      0.094594   \n",
       "1   153.735422   161.946505                                      0.052033   \n",
       "2    97.298658    97.750542                                      0.222297   \n",
       "3   153.400466   155.280630                                      0.201326   \n",
       "4   133.425556   151.094102                                      0.116144   \n",
       "\n",
       "   sift_match_percentage_with_belakang_10k.jpg  \\\n",
       "0                                     0.174736   \n",
       "1                                     0.212724   \n",
       "2                                     0.092062   \n",
       "3                                     0.267918   \n",
       "4                                     0.223179   \n",
       "\n",
       "   sift_match_percentage_with_belakang_1k.jpg  \\\n",
       "0                                    0.059121   \n",
       "1                                    0.021425   \n",
       "2                                    0.042663   \n",
       "3                                    0.034070   \n",
       "4                                    0.034160   \n",
       "\n",
       "   sift_match_percentage_with_belakang_20k.jpg  ...  \\\n",
       "0                                     0.063062  ...   \n",
       "1                                     0.035199  ...   \n",
       "2                                     0.083081  ...   \n",
       "3                                     0.068141  ...   \n",
       "4                                     0.063765  ...   \n",
       "\n",
       "   orb_match_percentage_with_belakang_2k.jpg  \\\n",
       "0                                        2.0   \n",
       "1                                        1.8   \n",
       "2                                        2.6   \n",
       "3                                        2.2   \n",
       "4                                        2.0   \n",
       "\n",
       "   orb_match_percentage_with_belakang_50k.jpg  \\\n",
       "0                                         2.0   \n",
       "1                                         1.8   \n",
       "2                                         2.4   \n",
       "3                                         2.2   \n",
       "4                                         2.0   \n",
       "\n",
       "   orb_match_percentage_with_belakang_5k.jpg  \\\n",
       "0                                        1.8   \n",
       "1                                        1.8   \n",
       "2                                        2.0   \n",
       "3                                        1.6   \n",
       "4                                        2.4   \n",
       "\n",
       "   orb_match_percentage_with_depan_100k.jpg  \\\n",
       "0                                       2.0   \n",
       "1                                       1.8   \n",
       "2                                       2.0   \n",
       "3                                       2.0   \n",
       "4                                       1.8   \n",
       "\n",
       "   orb_match_percentage_with_depan_10k.jpg  \\\n",
       "0                                      2.0   \n",
       "1                                      2.2   \n",
       "2                                      2.0   \n",
       "3                                      2.2   \n",
       "4                                      2.2   \n",
       "\n",
       "   orb_match_percentage_with_depan_1k.jpg  \\\n",
       "0                                     1.6   \n",
       "1                                     2.0   \n",
       "2                                     2.4   \n",
       "3                                     1.6   \n",
       "4                                     2.0   \n",
       "\n",
       "   orb_match_percentage_with_depan_20k.jpg  \\\n",
       "0                                      2.0   \n",
       "1                                      2.0   \n",
       "2                                      2.4   \n",
       "3                                      2.4   \n",
       "4                                      2.2   \n",
       "\n",
       "   orb_match_percentage_with_depan_2k.jpg  \\\n",
       "0                                     1.8   \n",
       "1                                     1.6   \n",
       "2                                     2.0   \n",
       "3                                     1.8   \n",
       "4                                     1.8   \n",
       "\n",
       "   orb_match_percentage_with_depan_50k.jpg  \\\n",
       "0                                      2.0   \n",
       "1                                      1.8   \n",
       "2                                      2.4   \n",
       "3                                      2.0   \n",
       "4                                      1.8   \n",
       "\n",
       "   orb_match_percentage_with_depan_5k.jpg  \n",
       "0                                     1.8  \n",
       "1                                     1.8  \n",
       "2                                     2.2  \n",
       "3                                     2.0  \n",
       "4                                     1.8  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp_classification_df = pd.read_csv(\"rupiah_classification.csv\")\n",
    "rp_classification_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
